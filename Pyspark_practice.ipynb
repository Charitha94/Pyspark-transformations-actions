{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc, jsparkSession=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.101.249:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe06d755990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Download the dataset from kaggle - https://www.kaggle.com/datasets/rodsaldanha/arketing-campaign?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data into a dataframe\n",
    "\n",
    "mrkt_df = spark.read.option(\"inferSchema\",\"true\").option(\"header\",\"true\").option(\"delimiter\", \"\\t\").csv(\"/Users/charithaveeragandham/Downloads/marketing_campaign.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "#Total number of columns\n",
    "\n",
    "print(len(mrkt_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Year_Birth: integer (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Marital_Status: string (nullable = true)\n",
      " |-- Income: integer (nullable = true)\n",
      " |-- Kidhome: integer (nullable = true)\n",
      " |-- Teenhome: integer (nullable = true)\n",
      " |-- Dt_Customer: string (nullable = true)\n",
      " |-- Recency: integer (nullable = true)\n",
      " |-- MntWines: integer (nullable = true)\n",
      " |-- MntFruits: integer (nullable = true)\n",
      " |-- MntMeatProducts: integer (nullable = true)\n",
      " |-- MntFishProducts: integer (nullable = true)\n",
      " |-- MntSweetProducts: integer (nullable = true)\n",
      " |-- MntGoldProds: integer (nullable = true)\n",
      " |-- NumDealsPurchases: integer (nullable = true)\n",
      " |-- NumWebPurchases: integer (nullable = true)\n",
      " |-- NumCatalogPurchases: integer (nullable = true)\n",
      " |-- NumStorePurchases: integer (nullable = true)\n",
      " |-- NumWebVisitsMonth: integer (nullable = true)\n",
      " |-- AcceptedCmp3: integer (nullable = true)\n",
      " |-- AcceptedCmp4: integer (nullable = true)\n",
      " |-- AcceptedCmp5: integer (nullable = true)\n",
      " |-- AcceptedCmp1: integer (nullable = true)\n",
      " |-- AcceptedCmp2: integer (nullable = true)\n",
      " |-- Complain: integer (nullable = true)\n",
      " |-- Z_CostContact: integer (nullable = true)\n",
      " |-- Z_Revenue: integer (nullable = true)\n",
      " |-- Response: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printSchema() display schema of a dataframe i.e columns, thier datatypes and whether they are nullable\n",
    "mrkt_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| ID| Name|Salary|\n",
      "+---+-----+------+\n",
      "|  1|Name1|  5000|\n",
      "|  2|Name2|  7000|\n",
      "|  3|Name3|  8000|\n",
      "|  4|Name4| 10000|\n",
      "|  5|Name5|  9000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#Sample data creation\n",
    "data = ([\n",
    "        (1,\"Name1\",5000),\n",
    "        (2,\"Name2\",7000),\n",
    "        (3,\"Name3\",8000),\n",
    "        (4,\"Name4\",10000),\n",
    "        (5,\"Name5\",9000)\n",
    "])\n",
    "\n",
    "#Defining the schema\n",
    "schema = StructType([\n",
    "            StructField(\"ID\",IntegerType(),True),\n",
    "            StructField(\"Name\",StringType(),True),\n",
    "            StructField(\"Salary\",IntegerType(),True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data,schema)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Actions are operations that display data from datasets. Transformations are executed when an action is called. \n",
    "1. show()\n",
    "2. collect()\n",
    "3. take()\n",
    "4. first() or head()\n",
    "5. saveAsTextFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> show() is an action that is used to display entries from a dataframe\n",
    "-> show(truncate=false/true) controls display of entire string in a column \n",
    "-> By default, show() display 20 rows\n",
    "-> show(n) displays n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| ID| Name|Salary|\n",
      "+---+-----+------+\n",
      "|  1|Name1|  5000|\n",
      "|  2|Name2|  7000|\n",
      "|  3|Name3|  8000|\n",
      "|  4|Name4| 10000|\n",
      "|  5|Name5|  9000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> collect() fetches all elements from a dataframe hence should be avoided\n",
    "-> Should be used on a smaller dataset\n",
    "-> return entire dataset in array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=1, Name='Name1', Salary=5000),\n",
       " Row(ID=2, Name='Name2', Salary=7000),\n",
       " Row(ID=3, Name='Name3', Salary=8000),\n",
       " Row(ID=4, Name='Name4', Salary=10000),\n",
       " Row(ID=5, Name='Name5', Salary=9000)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take(), first() and head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> take() recieved an integer n and returns n rows from a dataset in the format of an array\n",
    "-> take(1) is same as first() and head() except take displays results in an array\n",
    "-> first() and head() display first row in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=1, Name='Name1', Salary=5000),\n",
       " Row(ID=2, Name='Name2', Salary=7000),\n",
       " Row(ID=3, Name='Name3', Salary=8000),\n",
       " Row(ID=4, Name='Name4', Salary=10000)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ID=1, Name='Name1', Salary=5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Following 3 actions yield the same results\n",
    "\n",
    "#Result type [row(cname1=val1,cname2=val2)]\n",
    "df.take(1) \n",
    "#Result type row(cname1=val1,cname2=val2)\n",
    "df.head() \n",
    "df.first()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saveAsTextFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveAsTextFile() is an RDD action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the dataframe to an RDD since this action is not available for a dataframe\n",
    "df.rdd.saveAsTextFile('saverdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['._SUCCESS.crc',\n",
       " '.part-00000.crc',\n",
       " '.part-00001.crc',\n",
       " 'part-00002',\n",
       " '.part-00003.crc',\n",
       " 'part-00003',\n",
       " '.part-00002.crc',\n",
       " '_SUCCESS',\n",
       " 'part-00001',\n",
       " 'part-00000']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('saverdd')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> saveAsTextFile() saves an RDD in the given directory.\n",
    "-> It creates the directory if it doesn't exists\n",
    "-> It loads the data of an RDD in part files\n",
    "-> Note that there are a total of 4 partitions and hence there are 4 part file - Ignore *.crc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a dataframe to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataframe can be written to a file using write() and save() methods\n",
    "\n",
    "#Both of these statament perform the same operation\n",
    "#df.write.csv(\"savedf\")\n",
    "df.write.format(\"csv\").save(\"savedf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['._SUCCESS.crc',\n",
       " '.part-00000-6dcbef47-26f8-4e2e-8140-ab8d15d24f9a-c000.csv.crc',\n",
       " 'part-00003-6dcbef47-26f8-4e2e-8140-ab8d15d24f9a-c000.csv',\n",
       " '.part-00001-6dcbef47-26f8-4e2e-8140-ab8d15d24f9a-c000.csv.crc',\n",
       " '.part-00003-6dcbef47-26f8-4e2e-8140-ab8d15d24f9a-c000.csv.crc',\n",
       " '.part-00002-6dcbef47-26f8-4e2e-8140-ab8d15d24f9a-c000.csv.crc',\n",
       " 'part-00002-6dcbef47-26f8-4e2e-8140-ab8d15d24f9a-c000.csv',\n",
       " '_SUCCESS',\n",
       " 'part-00001-6dcbef47-26f8-4e2e-8140-ab8d15d24f9a-c000.csv',\n",
       " 'part-00000-6dcbef47-26f8-4e2e-8140-ab8d15d24f9a-c000.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('savedf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Transformations are operations that result in a new dataframe\n",
    "1. select()\n",
    "2. selectExpr()\n",
    "3. map()\n",
    "4. flatMap()\n",
    "5. filter() \n",
    "6. where()\n",
    "7. withColumn()\n",
    "8. coalesce()\n",
    "9. repartition()\n",
    "10. join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> Dataframes, RDDs and Datasets are immutable\n",
    "-> select() - It is a transformation and is used to select columns from a df. It can take columns, list and str as input.\n",
    "-> selectExpr() - Similar to select() but the main difference is that it can take SQL expressions. Accepts only str.\n",
    "-> Both select() and selectExpr() results in a new df because they are transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------------+------+-------+--------+-------+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|\n",
      "+----+----------+--------------+------+-------+--------+-------+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     58|\n",
      "|2174|      1954|        Single| 46344|      1|       1|     38|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     26|\n",
      "|6182|      1984|      Together| 26646|      1|       0|     26|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     94|\n",
      "|7446|      1967|      Together| 62513|      0|       1|     16|\n",
      "| 965|      1971|      Divorced| 55635|      0|       1|     34|\n",
      "|6177|      1985|       Married| 33454|      1|       0|     32|\n",
      "|4855|      1974|      Together| 30351|      1|       0|     19|\n",
      "|5899|      1950|      Together|  5648|      1|       1|     68|\n",
      "+----+----------+--------------+------+-------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example of select\n",
    "\n",
    "columns_subset1 = ['ID','Year_Birth','Marital_Status','Income','Kidhome','Teenhome','Recency']\n",
    "\n",
    "select_df = mrkt_df.select(columns_subset1)\n",
    "\n",
    "select_df.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|Income_bracket|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     58|          high|\n",
      "|2174|      1954|        Single| 46344|      1|       1|     38|           low|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     26|          high|\n",
      "|6182|      1984|      Together| 26646|      1|       0|     26|           low|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     94|          high|\n",
      "|7446|      1967|      Together| 62513|      0|       1|     16|          high|\n",
      "| 965|      1971|      Divorced| 55635|      0|       1|     34|          high|\n",
      "|6177|      1985|       Married| 33454|      1|       0|     32|           low|\n",
      "|4855|      1974|      Together| 30351|      1|       0|     19|           low|\n",
      "|5899|      1950|      Together|  5648|      1|       1|     68|           low|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------+\n",
      "|Income_Range|\n",
      "+------------+\n",
      "|        high|\n",
      "|         low|\n",
      "|        high|\n",
      "|         low|\n",
      "|        high|\n",
      "|        high|\n",
      "|        high|\n",
      "|         low|\n",
      "|         low|\n",
      "|         low|\n",
      "+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- Income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example of selectExpr()\n",
    "\n",
    "expr_df = select_df.selectExpr(\"*\",(\"case when Income<50000 then 'low' else 'high' end as Income_bracket\"))\n",
    "expr_df.show(n=10)\n",
    "\n",
    "#Changing col name using selectExpr()\n",
    "expr_df.selectExpr(\"Income_bracket as Income_Range\").show(n=10)\n",
    "\n",
    "#Changing column type - Income was initially of type Int\n",
    "expr_df.selectExpr(\"cast(Income as String)\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map() vs flatMap()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> Both map() and flatMap() are rdd transformations\n",
    "-> map() - It is a transformation that applied a function to each row in a dataset. No. of rows in input and output df remains the same\n",
    "-> flatMap() - Similar to map() but it results in a df with more than the input df. It is a one-many transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|  ID|Age|\n",
      "+----+---+\n",
      "|5524| 65|\n",
      "|2174| 68|\n",
      "|4141| 57|\n",
      "|6182| 38|\n",
      "|5324| 41|\n",
      "|7446| 55|\n",
      "| 965| 51|\n",
      "|6177| 37|\n",
      "|4855| 48|\n",
      "|5899| 72|\n",
      "|1994| 39|\n",
      "| 387| 46|\n",
      "|2125| 63|\n",
      "|8180| 70|\n",
      "|2569| 35|\n",
      "|2114| 76|\n",
      "|9736| 42|\n",
      "|4939| 76|\n",
      "|6565| 73|\n",
      "|2278| 37|\n",
      "+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example of map()\n",
    "\n",
    "age_df=expr_df.rdd.map(lambda x: (x.ID,2022-x.Year_Birth)).toDF().selectExpr(\"_1 as ID\",\"_2 as Age\")\n",
    "\n",
    "age_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|       _1|count|\n",
      "+---------+-----+\n",
      "|   steps.|    1|\n",
      "|     bar.|    1|\n",
      "|  appears|    1|\n",
      "| document|    1|\n",
      "|      you|    1|\n",
      "|      for|    1|\n",
      "|    Pages|    2|\n",
      "|     Open|    1|\n",
      "|    these|    1|\n",
      "|     your|    2|\n",
      "|   bottom|    1|\n",
      "|       on|    1|\n",
      "|document,|    1|\n",
      "|   count.|    1|\n",
      "|     View|    1|\n",
      "|     Show|    1|\n",
      "|      the|    6|\n",
      "|     want|    1|\n",
      "|      box|    1|\n",
      "|      see|    2|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To explain flatMap(), let us implement the word count problem\n",
    "\n",
    "text = \"This is a word count program. We first split the file and assign a value of one for each word. A groupBy is applied to count to number of times a word is repeated\"\n",
    "\n",
    "text = sc.textFile(\"file.txt\")\n",
    "\n",
    "text.flatMap(lambda x: x.split(\" \")).map(lambda x : (x,1)).toDF().groupBy(\"_1\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter() and where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|Income_bracket|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     58|          high|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     26|          high|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     94|          high|\n",
      "|7446|      1967|      Together| 62513|      0|       1|     16|          high|\n",
      "| 965|      1971|      Divorced| 55635|      0|       1|     34|          high|\n",
      "|1994|      1983|       Married|  null|      1|       0|     11|          high|\n",
      "|2125|      1959|      Divorced| 63033|      0|       0|     82|          high|\n",
      "|8180|      1952|      Divorced| 59354|      1|       1|     53|          high|\n",
      "|2114|      1946|        Single| 82800|      0|       0|     23|          high|\n",
      "|6565|      1949|       Married| 76995|      0|       1|     91|          high|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|Income_bracket|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     58|          high|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     26|          high|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     94|          high|\n",
      "|7446|      1967|      Together| 62513|      0|       1|     16|          high|\n",
      "| 965|      1971|      Divorced| 55635|      0|       1|     34|          high|\n",
      "|1994|      1983|       Married|  null|      1|       0|     11|          high|\n",
      "|2125|      1959|      Divorced| 63033|      0|       0|     82|          high|\n",
      "|8180|      1952|      Divorced| 59354|      1|       1|     53|          high|\n",
      "|2114|      1946|        Single| 82800|      0|       0|     23|          high|\n",
      "|6565|      1949|       Married| 76995|      0|       1|     91|          high|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filter() and where() transformations are used to filter rows based on the condition given\n",
    "\n",
    "expr_df.filter(expr_df.Income_bracket == \"high\").show(10)\n",
    "\n",
    "expr_df.where(expr_df.Income_bracket == \"high\").show(10)\n",
    "\n",
    "# As you can see both of these transformations perform the same operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## withColumn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "withColumn\n",
    "-> It is a transformation used along with df\n",
    "-> It is used to rename a column\n",
    "-> Can be used to change the data type\n",
    "-> Create new column and a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------------+------+-------+--------+-------+--------------+---+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|Income_bracket|Age|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+---+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     58|          high| 65|\n",
      "|2174|      1954|        Single| 46344|      1|       1|     38|           low| 68|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     26|          high| 57|\n",
      "|6182|      1984|      Together| 26646|      1|       0|     26|           low| 38|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     94|          high| 41|\n",
      "|7446|      1967|      Together| 62513|      0|       1|     16|          high| 55|\n",
      "| 965|      1971|      Divorced| 55635|      0|       1|     34|          high| 51|\n",
      "|6177|      1985|       Married| 33454|      1|       0|     32|           low| 37|\n",
      "|4855|      1974|      Together| 30351|      1|       0|     19|           low| 48|\n",
      "|5899|      1950|      Together|  5648|      1|       1|     68|           low| 72|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+---+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----+----------+--------------+------+-------+--------+-------+------------+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|Income_range|\n",
      "+----+----------+--------------+------+-------+--------+-------+------------+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     58|        high|\n",
      "|2174|      1954|        Single| 46344|      1|       1|     38|         low|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     26|        high|\n",
      "|6182|      1984|      Together| 26646|      1|       0|     26|         low|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     94|        high|\n",
      "+----+----------+--------------+------+-------+--------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+--------+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|Income_bracket|Use-case|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+--------+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     58|          high|Tutorial|\n",
      "|2174|      1954|        Single| 46344|      1|       1|     38|           low|Tutorial|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     26|          high|Tutorial|\n",
      "|6182|      1984|      Together| 26646|      1|       0|     26|           low|Tutorial|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     94|          high|Tutorial|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|Income_bracket|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     28|          high|\n",
      "|2174|      1954|        Single| 46344|      1|       1|      8|           low|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     -4|          high|\n",
      "|6182|      1984|      Together| 26646|      1|       0|     -4|           low|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     64|          high|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Year_Birth: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Year_Birth: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Year_Birth: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "#Create a new columns \n",
    "expr_df.withColumn(\"Age\",2022-col(\"Year_Birth\")).show(n=10)\n",
    "\n",
    "#Rename a column\n",
    "expr_df.withColumnRenamed(\"Income_bracket\",\"Income_range\").show(n=5)\n",
    "\n",
    "#Adding a new column using withColumn and lit\n",
    "expr_df.withColumn(\"Use-case\",lit(\"Tutorial\")).show(n=5)\n",
    "\n",
    "#Updating an existing column value\n",
    "expr_df.withColumn(\"Recency\",col(\"Recency\")-30).show(n=5)\n",
    "\n",
    "#Changing datatype of a column\n",
    "expr_df.select(\"Year_Birth\").printSchema()\n",
    "expr_df.withColumn(\"Year_Birth\",col(\"Year_Birth\").cast(\"string\")).select(\"Year_Birth\").printSchema()\n",
    "expr_df.select(\"Year_Birth\").printSchema()\n",
    "\n",
    "#As you see here, the second expr_df.select(\"Year_Birth\").printSchema() statement shows you that the dataframes are immutable\n",
    "#In order to store these changes, a new dataframe should be created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coalesce() and Repartition()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coalesce() \n",
    "-> It is used to decrease number of partiions. \n",
    "-> Performs better when reducing the partitions\n",
    "-> Minimal shuffle\n",
    "\n",
    "Repartition()\n",
    "-> It is used to either increase of decrease number of partitions\n",
    "-> Performs better when increasing the number partitions\n",
    "-> Full shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of repartition()\n",
    "\n",
    "expr_df.rdd.getNumPartitions()\n",
    "\n",
    "expr_df.rdd.repartition(2).getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of coalesce()\n",
    "\n",
    "expr_df.rdd.coalesce(1).getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "join() is used to join 2 dataframes based on a join column. It takes type of join as one of the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      "\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+----+---+\n",
      "|  ID|Year_Birth|Marital_Status|Income|Kidhome|Teenhome|Recency|Income_bracket|  ID|Age|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+----+---+\n",
      "|5524|      1957|        Single| 58138|      0|       0|     58|          high|5524| 65|\n",
      "|2174|      1954|        Single| 46344|      1|       1|     38|           low|2174| 68|\n",
      "|4141|      1965|      Together| 71613|      0|       0|     26|          high|4141| 57|\n",
      "|6182|      1984|      Together| 26646|      1|       0|     26|           low|6182| 38|\n",
      "|5324|      1981|       Married| 58293|      1|       0|     94|          high|5324| 41|\n",
      "|7446|      1967|      Together| 62513|      0|       1|     16|          high|7446| 55|\n",
      "| 965|      1971|      Divorced| 55635|      0|       1|     34|          high| 965| 51|\n",
      "|6177|      1985|       Married| 33454|      1|       0|     32|           low|6177| 37|\n",
      "|4855|      1974|      Together| 30351|      1|       0|     19|           low|4855| 48|\n",
      "|5899|      1950|      Together|  5648|      1|       1|     68|           low|5899| 72|\n",
      "|1994|      1983|       Married|  null|      1|       0|     11|          high|1994| 39|\n",
      "| 387|      1976|       Married|  7500|      0|       0|     59|           low| 387| 46|\n",
      "|2125|      1959|      Divorced| 63033|      0|       0|     82|          high|2125| 63|\n",
      "|8180|      1952|      Divorced| 59354|      1|       1|     53|          high|8180| 70|\n",
      "|2569|      1987|       Married| 17323|      0|       0|     38|           low|2569| 35|\n",
      "|2114|      1946|        Single| 82800|      0|       0|     23|          high|2114| 76|\n",
      "|9736|      1980|       Married| 41850|      1|       1|     51|           low|9736| 42|\n",
      "|4939|      1946|      Together| 37760|      0|       0|     20|           low|4939| 76|\n",
      "|6565|      1949|       Married| 76995|      0|       1|     91|          high|6565| 73|\n",
      "|2278|      1985|        Single| 33812|      1|       0|     86|           low|2278| 37|\n",
      "+----+----------+--------------+------+-------+--------+-------+--------------+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_df.printSchema()\n",
    "expr_df.join(age_df, age_df.ID==expr_df.ID,how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
